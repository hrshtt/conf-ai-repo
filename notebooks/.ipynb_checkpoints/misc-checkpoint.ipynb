{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo apt update\n",
    "!sudo apt install tor \n",
    "!pip install fake_useragent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ write the text from the following cell to: /etc/tor/torrc ############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Configuration file for a typical Tor user\n",
    "## Last updated 22 December 2017 for Tor 0.3.2.8-rc.\n",
    "## (may or may not work for much older or much newer versions of Tor.)\n",
    "##\n",
    "## Lines that begin with \"## \" try to explain what's going on. Lines\n",
    "## that begin with just \"#\" are disabled commands: you can enable them\n",
    "## by removing the \"#\" symbol.\n",
    "##\n",
    "## See 'man tor', or https://www.torproject.org/docs/tor-manual.html,\n",
    "## for more options you can use in this file.\n",
    "##\n",
    "## Tor will look for this file in various places based on your platform:\n",
    "## https://www.torproject.org/docs/faq#torrc\n",
    "\n",
    "## Tor opens a SOCKS proxy on port 9050 by default -- even if you don't\n",
    "## configure one below. Set \"SOCKSPort 0\" if you plan to run Tor only\n",
    "## as a relay, and not make any local application connections yourself.\n",
    "# SOCKSPort 9050 # Default: Bind to localhost:9050 for local connections.\n",
    "#SOCKSPort 192.168.0.1:9100 # Bind to this address:port too.\n",
    "\n",
    "## Entry policies to allow/deny SOCKS requests based on IP address.\n",
    "## First entry that matches wins. If no SOCKSPolicy is set, we accept\n",
    "## all (and only) requests that reach a SOCKSPort. Untrusted users who\n",
    "## can access your SOCKSPort may be able to learn about the connections\n",
    "## you make.\n",
    "#SOCKSPolicy accept 192.168.0.0/16\n",
    "#SOCKSPolicy accept6 FC00::/7\n",
    "#SOCKSPolicy reject *\n",
    "\n",
    "## Logs go to stdout at level \"notice\" unless redirected by something\n",
    "## else, like one of the below lines. You can have as many Log lines as\n",
    "## you want.\n",
    "##\n",
    "## We advise using \"notice\" in most cases, since anything more verbose\n",
    "## may provide sensitive information to an attacker who obtains the logs.\n",
    "##\n",
    "## Send all messages of level 'notice' or higher to /var/log/tor/notices.log\n",
    "#Log notice file /var/log/tor/notices.log\n",
    "## Send every possible message to /var/log/tor/debug.log\n",
    "#Log debug file /var/log/tor/debug.log\n",
    "## Use the system log instead of Tor's logfiles\n",
    "#Log notice syslog\n",
    "## To send all messages to stderr:\n",
    "#Log debug stderr\n",
    "\n",
    "## Uncomment this to start the process in the background... or use\n",
    "## --runasdaemon 1 on the command line. This is ignored on Windows;\n",
    "## see the FAQ entry if you want Tor to run as an NT service.\n",
    "#RunAsDaemon 1\n",
    "\n",
    "## The directory for keeping all the keys/etc. By default, we store\n",
    "## things in $HOME/.tor on Unix, and in Application Data\\tor on Windows.\n",
    "#DataDirectory /var/lib/tor\n",
    "\n",
    "## The port on which Tor will listen for local connections from Tor\n",
    "## controller applications, as documented in control-spec.txt.\n",
    "ControlPort 9051\n",
    "## If you enable the controlport, be sure to enable one of these\n",
    "## authentication methods, to prevent attackers from accessing it.\n",
    "#HashedControlPassword 16:872860B76453A77D60CA2BB8C1A7042072093276A3D701AD684053EC4C\n",
    "CookieAuthentication 1\n",
    "\n",
    "############### This section is just for location-hidden services ###\n",
    "\n",
    "## Once you have configured a hidden service, you can look at the\n",
    "## contents of the file \".../hidden_service/hostname\" for the address\n",
    "## to tell people.\n",
    "##\n",
    "## HiddenServicePort x y:z says to redirect requests on port x to the\n",
    "## address y:z.\n",
    "\n",
    "#HiddenServiceDir /var/lib/tor/hidden_service/\n",
    "#HiddenServicePort 80 127.0.0.1:80\n",
    "\n",
    "#HiddenServiceDir /var/lib/tor/other_hidden_service/\n",
    "#HiddenServicePort 80 127.0.0.1:80\n",
    "#HiddenServicePort 22 127.0.0.1:22\n",
    "\n",
    "################ This section is just for relays #####################\n",
    "#\n",
    "## See https://www.torproject.org/docs/tor-doc-relay for details.\n",
    "\n",
    "## Required: what port to advertise for incoming Tor connections.\n",
    "#ORPort 9001\n",
    "## If you want to listen on a port other than the one advertised in\n",
    "## ORPort (e.g. to advertise 443 but bind to 9090), you can do it as\n",
    "## follows.  You'll need to do ipchains or other port forwarding\n",
    "## yourself to make this work.\n",
    "#ORPort 443 NoListen\n",
    "#ORPort 127.0.0.1:9090 NoAdvertise\n",
    "\n",
    "## The IP address or full DNS name for incoming connections to your\n",
    "## relay. Leave commented out and Tor will guess.\n",
    "#Address noname.example.com\n",
    "\n",
    "## If you have multiple network interfaces, you can specify one for\n",
    "## outgoing traffic to use.\n",
    "## OutboundBindAddressExit will be used for all exit traffic, while\n",
    "## OutboundBindAddressOR will be used for all OR and Dir connections\n",
    "## (DNS connections ignore OutboundBindAddress).\n",
    "## If you do not wish to differentiate, use OutboundBindAddress to\n",
    "## specify the same address for both in a single line.\n",
    "#OutboundBindAddressExit 10.0.0.4\n",
    "#OutboundBindAddressOR 10.0.0.5\n",
    "\n",
    "## A handle for your relay, so people don't have to refer to it by key.\n",
    "## Nicknames must be between 1 and 19 characters inclusive, and must\n",
    "## contain only the characters [a-zA-Z0-9].\n",
    "#Nickname ididnteditheconfig\n",
    "\n",
    "## Define these to limit how much relayed traffic you will allow. Your\n",
    "## own traffic is still unthrottled. Note that RelayBandwidthRate must\n",
    "## be at least 75 kilobytes per second.\n",
    "## Note that units for these config options are bytes (per second), not\n",
    "## bits (per second), and that prefixes are binary prefixes, i.e. 2^10,\n",
    "## 2^20, etc.\n",
    "#RelayBandwidthRate 100 KBytes  # Throttle traffic to 100KB/s (800Kbps)\n",
    "#RelayBandwidthBurst 200 KBytes # But allow bursts up to 200KB (1600Kb)\n",
    "\n",
    "## Use these to restrict the maximum traffic per day, week, or month.\n",
    "## Note that this threshold applies separately to sent and received bytes,\n",
    "## not to their sum: setting \"40 GB\" may allow up to 80 GB total before\n",
    "## hibernating.\n",
    "##\n",
    "## Set a maximum of 40 gigabytes each way per period.\n",
    "#AccountingMax 40 GBytes\n",
    "## Each period starts daily at midnight (AccountingMax is per day)\n",
    "#AccountingStart day 00:00\n",
    "## Each period starts on the 3rd of the month at 15:00 (AccountingMax\n",
    "## is per month)\n",
    "#AccountingStart month 3 15:00\n",
    "\n",
    "## Administrative contact information for this relay or bridge. This line\n",
    "## can be used to contact you if your relay or bridge is misconfigured or\n",
    "## something else goes wrong. Note that we archive and publish all\n",
    "## descriptors containing these lines and that Google indexes them, so\n",
    "## spammers might also collect them. You may want to obscure the fact that\n",
    "## it's an email address and/or generate a new address for this purpose.\n",
    "##\n",
    "## If you are running multiple relays, you MUST set this option.\n",
    "##\n",
    "#ContactInfo Random Person <nobody AT example dot com>\n",
    "## You might also include your PGP or GPG fingerprint if you have one:\n",
    "#ContactInfo 0xFFFFFFFF Random Person <nobody AT example dot com>\n",
    "\n",
    "## Uncomment this to mirror directory information for others. Please do\n",
    "## if you have enough bandwidth.\n",
    "#DirPort 9030 # what port to advertise for directory connections\n",
    "## If you want to listen on a port other than the one advertised in\n",
    "## DirPort (e.g. to advertise 80 but bind to 9091), you can do it as\n",
    "## follows.  below too. You'll need to do ipchains or other port\n",
    "## forwarding yourself to make this work.\n",
    "#DirPort 80 NoListen\n",
    "#DirPort 127.0.0.1:9091 NoAdvertise\n",
    "## Uncomment to return an arbitrary blob of html on your DirPort. Now you\n",
    "## can explain what Tor is if anybody wonders why your IP address is\n",
    "## contacting them. See contrib/tor-exit-notice.html in Tor's source\n",
    "## distribution for a sample.\n",
    "#DirPortFrontPage /etc/tor/tor-exit-notice.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo /etc/init.d/tor restart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If using Colab:\n",
    "from google.colab import drive\n",
    "drive.mount('gdrive')port pandas as pd\n",
    "backup_path = '/content/gdrive/My Drive/Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from multiprocessing import Pool\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from pprint import pprint\n",
    "from pickle import dumps\n",
    "from fake_useragent import UserAgent\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from shutil import copyfile\n",
    "from collections import defaultdict\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "class networking:\n",
    "    def __init__(self):\n",
    "        self.min_count = 1200\n",
    "        self.count = 0\n",
    "        self.session = self.get_session()\n",
    "        self.ua = UserAgent()\n",
    "        self.headers = {\"User-Agent\": self.ua.random}\n",
    "\n",
    "    def get_session(self):\n",
    "        session = requests.session()\n",
    "        creds = str(random.randint(10000, 0x7fffffff)) + \\\n",
    "            \":\" + \"jigneshKaBadaBhai\"\n",
    "        session.proxies = {'http': 'socks5h://{}@localhost:9050'.format(\n",
    "            creds), 'https': 'socks5h://{}@localhost:9050'.format(creds)}\n",
    "        print(f'Creating New Session: {creds}')\n",
    "        return session\n",
    "\n",
    "    def get_response(self, url, retry_count=0):\n",
    "        if retry_count >= 5:\n",
    "            print(f'Could not get response from {url}')\n",
    "            return None\n",
    "\n",
    "        if self.count >= self.min_count:\n",
    "            self.session = self.get_session()\n",
    "            self.count = 0\n",
    "\n",
    "            print('Getting New Session, Just Cuz.')\n",
    "        try:\n",
    "\n",
    "            r = self.session.get(url, headers=self.headers, timeout=5)\n",
    "            if r.status_code == 200:\n",
    "                self.count += 1\n",
    "                content = r.content.decode(encoding=\"UTF-8\")\n",
    "                retry_count = 0\n",
    "                return BeautifulSoup(r.content.decode(encoding=\"UTF-8\"), \"lxml\")\n",
    "            else:\n",
    "                raise Exception('Random Error I guess')\n",
    "\n",
    "        except requests.exceptions.Timeout as e:\n",
    "\n",
    "            print(f'Request Timed Out for {url}')\n",
    "            print('Changing Proxy')\n",
    "            print(e)\n",
    "\n",
    "            retry_count += 1\n",
    "\n",
    "            self.session = self.get_session()\n",
    "            print(f'Trying {retry_count} time')\n",
    "\n",
    "            return self.get_response(url, retry_count)\n",
    "\n",
    "        except Exception as e:\n",
    "\n",
    "            print(f'Something Random Happened for {url}')\n",
    "            print('Changing Proxy')\n",
    "            print(e)\n",
    "\n",
    "            retry_count += 1\n",
    "\n",
    "            self.session = self.get_session()\n",
    "            print(f'Trying {retry_count} time')\n",
    "\n",
    "            return self.get_response(url, retry_count)\n",
    "\n",
    "    def get_session_ip(self):\n",
    "        self.check_ip(self.session)\n",
    "\n",
    "    def check_ip(self, session):\n",
    "        r = session.get('http://httpbin.org/ip')\n",
    "        print(r.text)\n",
    "\n",
    "\n",
    "network_util = networking()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world_postal_xml = \"https://worldpostalcode.com/sitemap.xml\"\n",
    "soup = network_util.get_response(world_postal_xml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worldpostal_url_map = [url.loc.text if url.loc.text.endswith(\"/\") else url.loc.text + \"/\" for url in soup.find_all(\"url\")]\n",
    "random.seed(42)\n",
    "random.shuffle(worldpostal_url_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['country', 'regions', 'place', 'codes']\n",
    "file_name = 'postal_codes_data.csv'\n",
    "\n",
    "\n",
    "def overwrite_file(OVERWRITE=False):\n",
    "    if OVERWRITE:\n",
    "        if input(\"ARE YOU SURE YOU WANT TO OVERWRITE THE FILE???[Type \\\"YES\\\" if you must.]: \") == \"YES\":\n",
    "            print(\"I HOPE YOU KNOW WHAT YOU'RE DOING.\")\n",
    "            pd.DataFrame(columns=columns).to_csv(file_name, index=False)\n",
    "\n",
    "        else:\n",
    "            print(\"\\nWhy are you risking your life like this??\")\n",
    "    else:\n",
    "        print(\"Cannot Overwrite File\\nYou're Safe, for now.\")\n",
    "\n",
    "\n",
    "def scrap_postal_codes(worldpostal_url_list):\n",
    "    row_list = []\n",
    "\n",
    "    write_n_rows = 5000\n",
    "    rows_count = 0\n",
    "    drive_back_up_after = 5\n",
    "    write_to_file_count = 0\n",
    "\n",
    "    total = len(worldpostal_url_list)\n",
    "\n",
    "    done = False\n",
    "\n",
    "    for i, url in enumerate(worldpostal_url_list):\n",
    "        try:\n",
    "            soup = network_util.get_response(url)\n",
    "            breadcrumb_list = [a.text for a in soup.find(\n",
    "                \"ul\", {\"itemtype\": \"http://schema.org/BreadcrumbList\"}).find_all(\"a\")]\n",
    "            _, country, *regions = breadcrumb_list\n",
    "\n",
    "            if soup.find(\"div\", {\"class\": \"codes\"}) is not None:\n",
    "                units_list = soup.find(\n",
    "                    \"div\", {\"class\": \"codes\"}).find_all(\"div\", \"unit\")\n",
    "                data = [[item.find(\"div\", {\"class\": \"place\"}).text, [code.text for code in item.find(\n",
    "                    \"div\", {\"class\": \"code\"}).find_all('span')]] for item in units_list]\n",
    "                places, codes = zip(*data)\n",
    "\n",
    "                for index in range(len(places)):\n",
    "                    row_list.append({\n",
    "                        'country': country,\n",
    "                        'regions': regions,\n",
    "                        'place': places[index],\n",
    "                        'codes': codes[index],\n",
    "                    })\n",
    "\n",
    "                    rows_count += 1\n",
    "\n",
    "            if i % 25 == 0:\n",
    "                print(f\"Got {len(data)} data rows from {url}\")\n",
    "                print(f\"Completed {i} of {total}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            continue\n",
    "\n",
    "        if rows_count >= write_n_rows:\n",
    "\n",
    "            clear_output(wait=True)\n",
    "\n",
    "            print(f\"Writing {len(row_list)} lines to file: {file_name} ...\")\n",
    "\n",
    "            pd.DataFrame(data=row_list, columns=columns).to_csv(\n",
    "                file_name, mode='a', header=False, index=False)\n",
    "\n",
    "            rows_count = 0\n",
    "            del row_list\n",
    "            row_list = []\n",
    "            write_to_file_count += 1\n",
    "            print(f\"{'**'*20}\\nCompleted {i} of {total}\\n{'**'*20}\")\n",
    "\n",
    "        if write_to_file_count >= drive_back_up_after:\n",
    "            print(f'{\"--\"*20}\\nBacking up files to drive\\n{\"--\"*20}')\n",
    "\n",
    "            copyfile(file_name, f'{backup_path}/{file_name}')\n",
    "            with open(f\"{backup_path}/last_index.txt\", \"w\") as f:\n",
    "                f.write(f\"{url} {i} out of {total}\")\n",
    "\n",
    "            write_to_file_count = 0\n",
    "\n",
    "        if i+1 == total:\n",
    "            print(f\"[FINAL] Got {len(data)} data rows from {url}\")\n",
    "            print(f\"[FINAL] Completed {i+1} of {total}\")\n",
    "\n",
    "            clear_output(wait=True)\n",
    "\n",
    "            print(\n",
    "                f\"[FINAL] Writing {len(row_list)} lines to file: {file_name} ...\")\n",
    "\n",
    "            pd.DataFrame(data=row_list, columns=columns).to_csv(\n",
    "                file_name, mode='a', header=False, index=False)\n",
    "\n",
    "            print(f'{\"--\"*20}\\n[FINAL] Backing up files to drive\\n{\"--\"*20}')\n",
    "\n",
    "            copyfile(file_name, f'{backup_path}/{file_name}')\n",
    "            with open(f\"{backup_path}/last_index.txt\", \"w\") as f:\n",
    "                f.write(f\"{url} {i} out of {total}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_list = []\n",
    "sub_region_list = []\n",
    "city_town_list = []\n",
    "\n",
    "for elem in df[\"regions\"]:\n",
    "    elem = eval(elem)\n",
    "    if len(elem) == 0:\n",
    "        region = ''\n",
    "        sub_region = ''\n",
    "        city_town = ''\n",
    "        \n",
    "    elif len(elem) == 1:\n",
    "        region = elem[0]\n",
    "        sub_region = ''\n",
    "        city_town = ''\n",
    "        \n",
    "    elif len(elem) == 2:\n",
    "        region = elem[0]\n",
    "        sub_region = elem[1]\n",
    "        city_town = ''\n",
    "        \n",
    "    elif len(elem) == 3:\n",
    "        region = elem[0]\n",
    "        sub_region = elem[1]\n",
    "        city_town = elem[2]\n",
    "        \n",
    "    else:\n",
    "        print(\"wtf\")\n",
    "        \n",
    "    region_list.append(region)\n",
    "    sub_region_list.append(sub_region)\n",
    "    city_town_list.append(city_town)\n",
    "    \n",
    "df['state/region'] = region_list\n",
    "df['sub-region'] = sub_region_list\n",
    "df['city/town'] = city_town_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns = ['regions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['country', 'place', 'codes', 'state/region', 'sub-region', 'city/town']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['country', 'state/region', 'sub-region', 'city/town', 'place', 'codes']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"/home/hrshtt/Downloads/postal_codes_[regions-seperated].csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.apply(lambda x: [eval(elem) for elem in x] if x.name == 'codes' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.explode('codes').to_csv(\"/home/hrshtt/Downloads/postal_codes_[regions-seperated, codes-exploded].csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
